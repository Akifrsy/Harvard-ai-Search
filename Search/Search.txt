Agent: Entity that perceives its environment and acts upon that environment

State: A configuration of the agent and its environment

Actions: Choices that can be made in a state
     -ACTIONS(s) returns the set of actions that can be executed in state 

Transition Model: A description of what state results from performing any applicable action in any state
     -Result(s, a) returns the state resulting from performing action a in state s

State Space: The set of all states reachable from the intial state by any sequence of actions

Goal Test: Way to determine whether a given state is a goal state

Path Cost: Numerical cost associated with a given path

Solution: A sequence of actions that leads from the initial state to a goal state

Optimal Solution: A solution that has the lowest path cost among all solutions



NODE;

a data structure that keeps track of 
     -a state
     -a parent (node that generated this node)
     -an action (action applied to parent to get node)
     -a path cost (from initial state to node)



APPROACH
     -Start with a frontier that contains the initial state.
     -Repeat:
	-If the frontier is empty, then no solution.
	-Remove a node from the frontier.
	-If node contains goal state, return the solution.
	-Expand node, add resulting nodes to the frontier.



Revised Approach: 
     -Start with a frontier that contains the intial state.
     -Start with an empty explored set.
     -Repeat:
	-If the frontier is empty, then no solution.
	-Remove a node from the frontier.
	-If node contains goal state, return the solution.
	-Add the node to the explored set.
	-Expand node, add resulting nodes to the frontier if they aren't already in the frontier or the explored set.

Stack: Last-in first-out data type

Depth-First Search: Search algorithm that always expands the deepst node in the frontier.

Breadth-First Search: Search algorithm that always expands the deepst node in the frontier.

Queue: First-in first-out data type.

Uninformed Search: Search strategy that uses no problem-specific knowledge.

Informed Search: Search strategy that uses problem-specific knowledge to find solutions more efficiently.

Greedy Best-First Search: Search algorithm that expands the node that is clotest to the goal, as estimated by a heuristic function.

A* Search: Search algorithm that expands node with lowest vale of g(n) + h(n)

     g(n) = cost to reach node
     h(n) = estimated cost to goal

A* Search: Optimal if
     -h(n) is admissible (never overestimates the true cost), and
     -h(n) is consistent (for every node n and successor n' with step cost c, h(n)<h(n') + c)



MINIMAX

     -MAX(X)aims to maximize score.
     -MIN(O)aims to minimize score.



GAME

     -So: Inital state.
     -Player(s): Returns which player to move in state.
     -Action(s): Returns legal moves in state.
     -Result(s, a): Returns state after action a taken in state.
     -Terminal(s): Checks if state s is a terminal state.
     -Utility(s): Final numerical value for terminal state.



Minimax
     -Given a state s:
	-MAX picks action a in ACTION(s) that produces highest value of MIN-VALUE(RESULT(s, a))
	-MIN picks action a in ACTION(s) that produces smallest value of MAX-VALUE(RESULT(s, a))


minimax
     function MIN-VALUE(state):
	if TERMINAL(state):
	  return UTILITY(state)
	  v = âˆž
	  for action in ACTIONS(state):
	     v = MIN(v, MAX-VALUE(RESULT(state, action)))

Evalution Function: Function that estimates the expected utility of the game from a given state